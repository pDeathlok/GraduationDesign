% This file was created with JabRef 2.9.2.
% Encoding: GBK

@TECHREPORT{Agency2007,
  author = {U£®S£®Environmental Protection Agency},
  title = {Report to Congress on Server and Data Center Energy Efficiency Public
	Law 109-431},
  institution = {U£®S£®Environmental Protection Agency},
  year = {2007}
}

@ARTICLE{Aksanli2012,
  author = {Aksanli, Baris and Venkatesh, Jagannathan and Rosing, Tajana imunic},
  title = {Using datacenter simulation to evaluate green energy integration},
  journal = {Computer},
  year = {2012},
  volume = {45},
  pages = {56--64},
  number = {9},
  abstract = {Many simulators are available to evaluate performance and power tradeoffs
	in datacenters. The authors use one such simulator to demonstrate
	that by accurately provisioning green energy availability for longer
	time intervals, green energy prediction can improve overall energy
	efficiency. 2012 IEEE.},
  address = {2001 L Street N.W., Suite 700, Washington, DC 20036-4928, United
	States},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20124015489081
	
	Data centers
	
	green computing
	
	Green energy
	
	Overall energy efficiency
	
	simulations
	
	Time interval},
  issn = {00189162},
  keywords = {Alternative fuels, Energy efficiency},
  publisher = {IEEE Computer Society}
}

@ARTICLE{Armbrust2010,
  author = {Armbrust, Michael and Fox, Armando and Griffith, Rean and Joseph,
	Anthony D. and Katz, Randy and Konwinski, Andy and Lee, Gunho and
	Patterson, David and Rabkin, Ariel and Stoica, Ion and Zaharia, Matei},
  title = {A view of cloud computing},
  journal = {Commun. ACM},
  year = {2010},
  volume = {53},
  pages = {50--58},
  number = {4},
  month = apr,
  acmid = {1721672},
  address = {New York, NY, USA},
  doi = {10.1145/1721654.1721672},
  issn = {0001-0782},
  issue_date = {April 2010},
  numpages = {9},
  publisher = {ACM},
  url = {http://doi.acm.org/10.1145/1721654.1721672}
}

@INPROCEEDINGS{AssunaoMD2010,
  author = {de Assunao MD and Gelas JP and Lefevre L and Orgerie AC},
  title = {The Green Grid'5000: Instrumenting and using a Grid with energy sensors},
  booktitle = {Proceedings of the 5th International Workshop on Distributed Cooperative
	Laboratories: Instrumenting the Grid(INGRID 2010)},
  year = {2010},
  address = {Poznan, Poland}
}

@INPROCEEDINGS{Barham2003,
  author = {Barham, Paul and Dragovic, Boris and Fraser, Keir and Hand, Steven
	and Harris, Tim and Ho, Alex and Neugebauer, Rolf and Pratt, Ian
	and Warfield, Andrew},
  title = {Xen and the art of virtualization},
  booktitle = {Operating Systems Review (ACM)},
  year = {2003},
  volume = {37},
  number = {5},
  pages = {164--177},
  address = {Lake George, NY, United states},
  publisher = {Association for Computing Machinery},
  abstract = {Numerous systems have been designed which use virtualization to subdivide
	the ample resources of a modern computer. Some require specialized
	hardware, or cannot support commodity operating systems. Some target
	100% binary compatibility at the expense of performance. Others sacrifice
	security or functionality for speed. Few offer resource isolation
	or performance guarantees; most provide only best-effort provisioning,
	risking denial of service. This paper presents Xen, an x86 virtual
	machine monitor which allows multiple commodity operating systems
	to share conventional hardware in a safe and resource managed fashion,
	but without sacrificing either performance or functionality. This
	is achieved by providing an idealized virtual machine abstraction
	to which operating systems such as Linux, BSD and Windows XP, can
	be ported with minimal effort. Our design is targeted at hosting
	up to 100 virtual machine instances simultaneously on a modern server.
	The virtualization approach taken by Xen is extremely efficient:
	we allow operating systems such as Linux and Windows XP to be hosted
	simultaneously for a negligible performance overhead - at most a
	few percent compared with the unvirtualized case. We considerably
	outperform competing commercial and freely available solutions in
	a range of microbenchmarks and system-wide tests. Copyright 2003
	ACM.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	2005299216115
	
	Hypervisions
	
	Paravirtualization
	
	Resource management
	
	Virtual machine monitors},
  issn = {01635980},
  keywords = {Computer operating systems, Benchmarking, Display devices, Resource
	allocation, Response time (computer systems), Servers, Switching}
}

@ARTICLE{Barroso2007,
  author = {Barroso, L.A. and Holzle, U.},
  title = {The Case for Energy-Proportional Computing},
  journal = {Computer},
  year = {2007},
  volume = {40},
  pages = {33-37},
  number = {12},
  doi = {10.1109/MC.2007.443},
  issn = {0018-9162},
  keywords = {disc storage;file servers;laptop computers;power aware computing;disk
	subsystem;energy usage profile;energy-proportional computing;energy-proportional
	design;laptop computer;memory subsystem;server energy saving;Computer
	crashes;Computer networks;Databases;Embedded computing;High performance
	computing;Large-scale systems;Network servers;Voltage;Web and internet
	services;Web server;energy-proportional computing;green computing}
}

@INPROCEEDINGS{Beck1996,
  author = {Beck, James E. and Siewiorek, Daniel P.},
  title = {Modeling multicomputer task allocation as a vector packing problem},
  booktitle = {Proceedings of the International Symposium on System Synthesis},
  year = {1996},
  pages = {115--120},
  address = {La Jolla, CA, USA},
  publisher = {IEEE},
  __markedentry = {[WangLong:]},
  abstract = {This paper considers the problem of task allocation for embedded,
	bus-based multicomputers. The problem is shown to be isomorphic to
	a generalization of vector packing, and heuristic solution techniques
	are investigated. A total of 256 packing algorithms are considered,
	using a divide-and-conquer experimentation strategy on a set of sixteen
	real and synthetic test cases. Performance is compared based on the
	number of processors, the utilization level of the broadcast bus
	and run time. This research differs from other approaches in that
	task allocation is formulated as a 'multi-dimensional' problem, and
	general purpose solution techniques are developed that can accommodate
	arbitrary models for the schedulable resources.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	1997083477574
	
	Heuristic algorithms
	
	Synchronous data flow graph},
  issn = {10801820},
  keywords = {Multiprocessing systems, Algorithms, Computer hardware, Computer software,
	Graph theory, Heuristic methods, Input output programs, Mathematical
	models, Program processors, Storage allocation (computer)}
}

@ARTICLE{Beloglazov2012,
  author = {Beloglazov, Anton and Abawajy, Jemal and Buyya, Rajkumar},
  title = {Energy-aware resource allocation heuristics for efficient management
	of data centers for Cloud computing},
  journal = {Future Generation Computer Systems},
  year = {2012},
  volume = {28},
  pages = {755--768},
  number = {5},
  abstract = {Cloud computing offers utility-oriented IT services to users worldwide.
	Based on a pay-as-you-go model, it enables hosting of pervasive applications
	from consumer, scientific, and business domains. However, data centers
	hosting Cloud applications consume huge amounts of electrical energy,
	contributing to high operational costs and carbon footprints to the
	environment. Therefore, we need Green Cloud computing solutions that
	can not only minimize operational costs but also reduce the environmental
	impact. In this paper, we define an architectural framework and principles
	for energy-efficient Cloud computing. Based on this architecture,
	we present our vision, open research challenges, and resource provisioning
	and allocation algorithms for energy-efficient management of Cloud
	computing environments. The proposed energy-aware allocation heuristics
	provision data center resources to client applications in a way that
	improves energy efficiency of the data center, while delivering the
	negotiated Quality of Service (QoS). In particular, in this paper
	we conduct a survey of research in energy-efficient computing and
	propose: (a) architectural principles for energy-efficient management
	of Clouds; (b) energy-efficient resource allocation policies and
	scheduling algorithms considering QoS expectations and power usage
	characteristics of the devices; and (c) a number of open research
	challenges, addressing which can bring substantial benefits to both
	resource providers and consumers. We have validated our approach
	by conducting a performance evaluation study using the CloudSim toolkit.
	The results demonstrate that Cloud computing model has immense potential
	as it offers significant cost savings and demonstrates high potential
	for the improvement of energy efficiency under dynamic workload scenarios.
	2011 Elsevier B.V. All rights reserved.},
  address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20120914807930
	
	Allocation algorithm
	
	Architectural frameworks
	
	Architectural principles
	
	Business domain
	
	Carbon footprint
	
	Client applications
	
	Computing environments
	
	Computing solutions
	
	Cost saving
	
	Data centers
	
	Dynamic consolidation
	
	Electrical energy
	
	Energy aware
	
	Energy efficient
	
	Energy-efficient resource allocation
	
	Green IT
	
	High potential
	
	IT services
	
	Operational costs
	
	Pay-as-you-go
	
	Performance evaluation
	
	Pervasive applications
	
	Power usage
	
	Research challenges
	
	Resource management
	
	Resource providers
	
	Resource provisioning
	
	Virtualizations},
  issn = {0167739X},
  keywords = {Cloud computing, Computer systems, Energy efficiency, Environmental
	impact, Quality of service, Research, Resource allocation},
  publisher = {Elsevier}
}

@INPROCEEDINGS{Beloglazov2012a,
  author = {Beloglazov, Anton and Buyya, Rajkumar},
  title = {Optimal online deterministic algorithms and adaptive heuristics for
	energy and performance efficient dynamic consolidation of virtual
	machines in Cloud data centers},
  booktitle = {Concurrency Computation Practice and Experience},
  year = {2012},
  volume = {24},
  number = {13},
  pages = {1397--1420},
  address = {Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom},
  publisher = {John Wiley and Sons Ltd},
  abstract = {The rapid growth in demand for computational power driven by modern
	service applications combined with the shift to the Cloud computing
	model have led to the establishment of large-scale virtualized data
	centers. Such data centers consume enormous amounts of electrical
	energy resulting in high operating costs and carbon dioxide emissions.
	Dynamic consolidation of virtual machines (VMs) using live migration
	and switching idle nodes to the sleep mode allows Cloud providers
	to optimize resource usage and reduce energy consumption. However,
	the obligation of providing high quality of service to customers
	leads to the necessity in dealing with the energy-performance trade-off,
	as aggressive consolidation may lead to performance degradation.
	Because of the variability of workloads experienced by modern applications,
	the VM placement should be optimized continuously in an online manner.
	To understand the implications of the online nature of the problem,
	we conduct a competitive analysis and prove competitive ratios of
	optimal online deterministic algorithms for the single VM migration
	and dynamic VM consolidation problems. Furthermore, we propose novel
	adaptive heuristics for dynamic consolidation of VMs based on an
	analysis of historical data from the resource usage by VMs. The proposed
	algorithms significantly reduce energy consumption, while ensuring
	a high level of adherence to the service level agreement. We validate
	the high efficiency of the proposed algorithms by extensive simulations
	using real-world workload traces from more than a thousand PlanetLab
	VMs. Copyright 2011 John Wiley Sons, Ltd. Copyright 2011 John Wiley
	Sons, Ltd.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20123515377637
	
	Adaptive heuristics
	
	Carbon dioxide emissions
	
	Cloud data
	
	Cloud providers
	
	Competitive analysis
	
	Competitive ratio
	
	Computational power
	
	Data centers
	
	Deterministic algorithms
	
	Dynamic consolidation
	
	Electrical energy
	
	Extensive simulations
	
	Green IT
	
	Historical data
	
	Live migrations
	
	Modern applications
	
	Modern service
	
	Performance degradation
	
	PlanetLab
	
	Rapid growth
	
	Resource management
	
	Resource usage
	
	Service Level Agreements
	
	SLEEP mode
	
	Virtual machines
	
	Virtualizations},
  issn = {15320626},
  keywords = {Algorithms, Carbon dioxide, Cloud computing, Computer simulation,
	Degradation, Energy utilization, Global warming, Optimization, Quality
	of service}
}

@ARTICLE{Beloglazov2012b,
  author = {Beloglazov, A. and Buyya, R.},
  title = {Managing Overloaded Hosts for Dynamic Consolidation of Virtual Machines
	in Cloud Data Centers Under Quality of Service Constraints},
  journal = {Parallel and Distributed Systems, IEEE Transactions on},
  year = {2012},
  volume = {PP},
  pages = {1--1},
  number = {99},
  abstract = {Dynamic consolidation of Virtual Machines (VMs) is an effective way
	to improve the utilization of resources and energy efficiency in
	Cloud data centers. Determining when it is best to reallocate VMs
	from an overloaded host is an aspect of dynamic VM consolidation
	that directly influences the resource utilization and Quality of
	Service (QoS) delivered by the system. The influence on the QoS is
	explained by the fact that server overloads cause resource shortages
	and performance degradation of applications. Current solutions to
	the problem of host overload detection are generally heuristic-based,
	or rely on statistical analysis of historical data. The limitations
	of these approaches are that they lead to sub-optimal results and
	do not allow explicit specification of a QoS goal. We propose a novel
	approach that for any known stationary workload and a given state
	configuration optimally solves the problem of host overload detection
	by maximizing the mean inter-migration time under the specified QoS
	goal based on a Markov chain model. We heuristically adapt the algorithm
	to handle unknown non-stationary workloads using the Multisize Sliding
	Window workload estimation technique. Through simulations with real-world
	workload traces from more than a thousand PlanetLab VMs, we show
	that our approach outperforms the best benchmark algorithm and provides
	approximately 88% of the performance of the optimal offline algorithm.},
  booktitle = {Parallel and Distributed Systems, IEEE Transactions on},
  issn = {1045-9219},
  keywords = {Communication/Networking and Information Technology, Computer Systems
	Organization, Distributed Systems, Emerging technologies, General,
	Markov processes, Mathematics of Computing, Modeling techniques,
	Performance of Systems, Probability and Statistics}
}

@INPROCEEDINGS{Beloglazov2010,
  author = {Beloglazov, Anton and Buyya, Rajkumar},
  title = {Adaptive threshold-based approach for energy-efficient consolidation
	of virtual machines in cloud data centers},
  booktitle = {Proceedings of the 8th International Workshop on Middleware for Grids,
	Clouds and e-Science},
  year = {2010},
  series = {MGC '10},
  pages = {4:1--4:6},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1890803},
  articleno = {4},
  doi = {10.1145/1890799.1890803},
  isbn = {978-1-4503-0453-5},
  keywords = {VM placement, cloud computing, green IT},
  location = {Bangalore, India},
  numpages = {6},
  url = {http://doi.acm.org/10.1145/1890799.1890803}
}

@ARTICLE{Berl2010,
  author = {Berl, Andreas and Gelenbe, Erol and Di Girolamo, Marco and Giuliani,
	Giovanni and De Meer, Hermann and Dang, Minh Quan and Pentikousis,
	Kostas},
  title = {Energy-efficient cloud computing},
  journal = {Computer Journal},
  year = {2010},
  volume = {53},
  pages = {1045--1051},
  number = {7},
  abstract = {Energy efficiency is increasingly important for future information
	and communication technologies (ICT), because the increased usage
	of ICT, together with increasing energy costs and the need to reduce
	green house gas emissions call for energy-efficient technologies
	that decrease the overall energy consumption of computation, storage
	and communications. Cloud computing has recently received considerable
	attention, as a promising approach for delivering ICT services by
	improving the utilization of data centre resources. In principle,
	cloud computing can be an inherently energy-efficient technology
	for ICT provided that its potential for significant energy savings
	that have so far focused on hardware aspects, can be fully explored
	with respect to system operation and networking aspects. Thus this
	paper, in the context of cloud computing, reviews the usage of methods
	and technologies currently used for energy-efficient operation of
	computer hardware and network infrastructure. After surveying some
	of the current best practice and relevant literature in this area,
	this paper identifies some of the remaining key research challenges
	that arise when such energy-saving techniques are extended for use
	in cloud computing environments. The Author 2009. Published by Oxford
	University Press on behalf of The British Computer Society. All rights
	reserved.},
  address = {Great Clarendon Street, Oxford, OX2 6DP, United Kingdom},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20103413167355
	
	Best-practices
	
	Cloud computing
	
	Data centres
	
	Energy aware
	
	Energy consumption
	
	Energy cost
	
	Energy efficient
	
	Energy saving
	
	Energy-saving techniques
	
	ICT services
	
	Information and Communication Technologies
	
	Network infrastructure
	
	Research challenges
	
	System operation},
  issn = {00104620},
  keywords = {Distributed computer systems, Computer hardware, Energy conservation,
	Energy efficiency, Energy utilization, Gas emissions, Greenhouse
	gases, Technology},
  publisher = {Oxford University Press}
}

@INPROCEEDINGS{Borgetto2012,
  author = {Borgetto, Damien and Maurer, Michael and Da-Costa, Georges and Pierson,
	Jean-Marc and Brandic, Ivona},
  title = {Energy-efficient and SLA-aware management of IaaS clouds},
  booktitle = {Proceedings of the 3rd International Conference on Future Energy
	Systems: Where Energy, Computing and Communication Meet},
  year = {2012},
  series = {e-Energy '12},
  pages = {25:1--25:10},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2208853},
  articleno = {25},
  doi = {10.1145/2208828.2208853},
  isbn = {978-1-4503-1055-0},
  keywords = {IaaS, algorithms, clouds, energy-efficiency, migration, reallocation,
	virtual machine},
  location = {Madrid, Spain},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/2208828.2208853}
}

@INPROCEEDINGS{Breitgand2012,
  author = {Breitgand, D. and Epstein, A.},
  title = {Improving consolidation of virtual machines with risk-aware bandwidth
	oversubscription in compute clouds},
  booktitle = {INFOCOM, 2012 Proceedings IEEE},
  year = {2012},
  pages = {2861--2865},
  abstract = {Current trends in virtualization, green computing, and cloud computing
	require ever increasing efficiency in consolidating virtual machines
	without degrading quality of service. In this work, we consider consolidating
	virtual machines on the minimum number of physical containers (e.g.,
	hosts or racks) in a cloud where the physical network (e.g., network
	interface or top of the rack switch link) may become a bottleneck.
	Since virtual machines do not simultaneously use maximum of their
	nominal bandwidth, the capacity of the physical container can be
	multiplexed. We assume that each virtual machine has a probabilistic
	guarantee on realizing its bandwidth Requirements-as derived from
	its Service Level Agreement with the cloud provider. Therefore, the
	problem of consolidating virtual machines on the minimum number of
	physical containers, while preserving these bandwidth allocation
	guarantees, can be modeled as a Stochastic Bin Packing (SBP) problem,
	where each virtual machine's bandwidth demand is treated as a random
	variable. We consider both offline and online versions of SBP. Under
	the assumption that the virtual machines' bandwidth consumption obeys
	normal distribution, we show a 2-approximation algorithm for the
	offline version and improve the previously reported results by presenting
	a (2 +&#x2208;)-competitive algorithm for the online version. We
	also observe that a dual polynomial-time approximation scheme (PTAS)
	for SBP can be obtained via reduction to the two-dimensional vector
	bin packing problem. Finally, we perform a thorough performance evaluation
	study using both synthetic and real data to evaluate the behavior
	of our proposed algorithms, showing their practical applicability.},
  issn = {0743-166X},
  keywords = {approximation theory, bin packing, cloud computing, computational
	complexity, environmental factors, normal distribution, risk management,
	software performance evaluation, virtual machines, virtualisation,
	2-approximation algorithm, 2D vector bin packing problem, PTAS, SBP
	problem, bandwidth allocation guarantees, bandwidth consumption,
	bandwidth requirements, bottleneck, cloud computing, dual polynomial-time
	approximation scheme, green computing, normal distribution, performance
	evaluation, physical containers, probabilistic guarantee, random
	variable, risk-aware bandwidth oversubscription, service level agreement,
	stochastic bin packing problem, virtual machines, virtualization,
	Approximation algorithms, Approximation methods, Bandwidth, Gaussian
	distribution, Random variables, Vectors, Virtual machining}
}

@INPROCEEDINGS{Buyya2008,
  author = {Buyya, Rajkumar and Yeo, Chee Shin and Venugopal, Srikumar},
  title = {Market-oriented cloud computing: Vision, hype, and reality for delivering
	IT services as computing utilities},
  booktitle = {Proceedings - 10th IEEE International Conference on High Performance
	Computing and Communications, HPCC 2008},
  year = {2008},
  pages = {5--13},
  address = {Dalian, China},
  publisher = {Inst. of Elec. and Elec. Eng. Computer Society},
  abstract = {This keynote paper: presents a 21st century vision of computing; identifies
	various computing paradigms promising to deliver the vision of computing
	utilities; defines Cloud computing and provides the architecture
	for creating market-oriented Clouds by leveraging technologies such
	as VMs; provides thoughts on market-based resource management strategies
	that encompass both customer-driven service management and computational
	risk management to sustain SLA-oriented resource allocation; presents
	some representative Cloud platforms especially those developed in
	industries along with our current work towards realising market-oriented
	resource allocation of Clouds by leveraging the 3 rd generation Aneka
	enterprise Grid technology; reveals our early thoughts on interconnecting
	Clouds for dynamically creating an atmospheric computing environment
	along with pointers to future community research; and concludes with
	the need for convergence of competing IT paradigms for delivering
	our 21st century vision. 2008 IEEE.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20084811737687
	
	Computational risk managements
	
	Computing environments
	
	Computing paradigms
	
	GRID technologies
	
	It services
	
	Resource Management strategies
	
	Service managements},
  keywords = {Grid computing, Clouds, Computer systems, High performance liquid
	chromatography, Information management, Management, Marketing, Planning,
	Resource allocation, Risk analysis, Risk management}
}

@ARTICLE{Calheiros2011,
  author = {Calheiros, Rodrigo N. and Ranjan, Rajiv and Beloglazov, Anton and
	De Rose, Cesar A. F. and Buyya, Rajkumar},
  title = {CloudSim: A toolkit for modeling and simulation of cloud computing
	environments and evaluation of resource provisioning algorithms},
  journal = {Software - Practice and Experience},
  year = {2011},
  volume = {41},
  pages = {23--50},
  number = {1},
  abstract = {Cloud computing is a recent advancement wherein IT infrastructure
	and applications are provided as 'services' to end-users under a
	usage-based payment model. It can leverage virtualized services even
	on the fly based on requirements (workload patterns and QoS) varying
	with time. The application services hosted under Cloud computing
	model have complex provisioning, composition, configuration, and
	deployment requirements. Evaluating the performance of Cloud provisioning
	policies, application workload models, and resources performance
	models in a repeatable manner under varying system and user configurations
	and requirements is difficult to achieve. To overcome this challenge,
	we propose CloudSim: an extensible simulation toolkit that enables
	modeling and simulation of Cloud computing systems and application
	provisioning environments. The CloudSim toolkit supports both system
	and behavior modeling of Cloud system components such as data centers,
	virtual machines (VMs) and resource provisioning policies. It implements
	generic application provisioning techniques that can be extended
	with ease and limited effort. Currently, it supports modeling and
	simulation of Cloud computing environments consisting of both single
	and inter-networked clouds (federation of clouds). Moreover, it exposes
	custom interfaces for implementing policies and provisioning techniques
	for allocation of VMs under inter-networked Cloud computing scenarios.
	Several researchers from organizations, such as HP Labs in U.S.A.,
	are using CloudSim in their investigation on Cloud resource provisioning
	and energy-efficient management of data center resources. The usefulness
	of CloudSim is demonstrated by a case study involving dynamic provisioning
	of application services in the hybrid federated clouds environment.
	The result of this case study proves that the federated Cloud computing
	model significantly improves the application QoS requirements under
	fluctuating resource and service demand patterns. Copyright 2010
	John Wiley Sons, Ltd.},
  address = {Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20110113550030
	
	Application scheduling
	
	Cloud computing
	
	Modelling and simulations
	
	Performance evaluation
	
	Resource management},
  issn = {00380644},
  keywords = {Distributed computer systems, Clouds, Computer simulation, Mathematical
	models, Natural resources management, Quality of service, Research,
	Resource allocation, Satellite communication systems},
  publisher = {John Wiley and Sons Ltd}
}

@INPROCEEDINGS{Chang2011,
  author = {Chang, Chao-Rui and Wu, Jan-Jan and Liu, Pangfeng},
  title = {An Empirical Study on Memory Sharing of Virtual Machines for Server
	Consolidation},
  booktitle = {Parallel and Distributed Processing with Applications (ISPA), 2011
	IEEE 9th International Symposium on},
  year = {2011},
  pages = {244--249},
  abstract = {Server consolidation presents numerous opportunities for sharing memory
	between virtual machines. To intelligently share RAM across VMs,
	modern hypervisors use a technique called content-based page sharing
	(CBPS), in which duplicate copies of a page resident on a host are
	detected and a single copy of the page is shared, thereby reducing
	the memory footprint of resident VMs. One widely used implementation
	of content-based page sharing is kernel same page merging (KSM).
	In this paper, we conduct empirical study on the effectiveness of
	KSM on various kinds of workload through extensive experiments. We
	classify memory sharing into two classes: static sharing for memory
	sharing after launching the VM and before executing the application,
	and dynamic sharing for memory sharing during the execution of the
	application. We found that KSM achieves very effective static memory
	sharing for various workload, evidenced by its ability to consolidate
	50 Windows VMs on one physical machine. KSM achieves most significant
	memory saving for mixed CPU and I/O workload. For CPU-bound applications,
	the effect of KSM on dynamic memory sharing is not as significant
	and it also causes higher runtime overhead. For I/O-bound applications,
	dynamic memory sharing reduces memory use by around 50% with very
	little runtime overhead. Furthermore, KSM has more significant effect
	on Windows based VMs than on Linux based VMs.},
  keywords = {Linux, content-based retrieval, network servers, random-access storage,
	shared memory systems, virtual machines, CPU- bound application,
	I/O-bound application, KSM, Linux, RAM, Windows VM, content-based
	page sharing, dynamic memory sharing, kernel same page merging, memory
	footprint, memory saving, page resident, physical machine, server
	consolidation, static memory sharing, virtual machine, Kernel, Linux,
	Memory management, Random access memory, Runtime, Servers, Virtual
	machining, memory sharing, server consolidation, virtual machine}
}

@INPROCEEDINGS{Clark2005,
  author = {Christopher Clark and Keir Fraser and Steven H and Jacob Gorm Hansen
	and Eric Jul and Christian Limpach and Ian Pratt and Andrew Warfield},
  title = {Live Migration of Virtual Machines},
  booktitle = {In Proceedings of the 2nd ACM/USENIX Symposium on Networked Systems
	Design and Implementation (NSDI},
  year = {2005},
  pages = {273--286},
  abstract = {Migrating operating system instances across distinct physical hosts
	is a useful tool for administrators of data centers and clusters:
	It allows a clean separation between hardware and software, and facilitates
	fault management, load balancing, and low-level system maintenance.
	
	By carrying out the majority of migration while OSes continue to run,
	we achieve impressive performance with minimal service downtimes;
	we demonstrate the migration of entire OS instances on a commodity
	cluster, recording service downtimes as low as 60ms. We show that
	that our performance is sufficient to make live migration a practical
	tool even for servers running interactive loads.
	
	
	In this paper we consider the design options for migrating OSes running
	services with liveness constraints, focusing on data center and cluster
	environments. We introduce and analyze the concept of writable working
	set, and present the design, implementation and evaluation of high-performance
	OS migration built on top of the Xen VMM.}
}

@MISC{poweredgeC6105,
  author = {Standard Performance Evaluation Corporation},
  title = {SPECpower_ssj2008 Dell Inc. PowerEdge C6105},
  howpublished = {http://www.spec.org/power_ssj2008/results/res2013q1/power_ssj2008-20121218-00591.html},
  month = {2},
  year = {2013}
}

@MISC{poweredgeC6145,
  author = {Standard Performance Evaluation Corporation},
  title = {SPECpower_ssj2008 Dell Inc. PowerEdge C6145},
  howpublished = {http://www.spec.org/power_ssj2008/results/res2013q1/power_ssj2008-20121218-00592.html},
  month = {2},
  year = {2013}
}

@INPROCEEDINGS{Deshpande2011,
  author = {Deshpande, Umesh and Wang, Xiaoshuang and Gopalan, Kartik},
  title = {Live gang migration of virtual machines},
  booktitle = {Proceedings of the IEEE International Symposium on High Performance
	Distributed Computing},
  year = {2011},
  pages = {135--146},
  address = {San Jose, CA, United states},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  __markedentry = {[WangLong:6]},
  abstract = {This paper addresses the problem of simultaneously migrating a group
	of co-located and live virtual machines (VMs), i.e, VMs executing
	on the same physical machine. We refer to such a mass simultaneous
	migration of active VMs as "live gang migration". Cluster administrators
	may often need to perform live gang migration for load balancing,
	system maintenance, or power savings. Application performance requirements
	may dictate that the total migration time, network traffic overhead,
	and service downtime, be kept minimal when migrating multiple VMs.
	State-of-the-art live migration techniques optimize the migration
	of a single VM. In this paper, we optimize the simultaneous live
	migration of multiple co-located VMs. We present the design, implementation,
	and evaluation of a de-duplication based approach to perform concurrent
	live migration of co-located VMs. Our approach transmits memory content
	that is identical across VMs only once during migration to significantly
	reduce both the total migration time and network traffic. Using the
	QEMU/KVM platform, we detail a proof-of-concept prototype implementation
	of two types of de-duplication strategies (at page level and sub-page
	level) and a differential compression approach to exploit content
	similarity across VMs. Evaluations over Gigabit Ethernet with various
	types of VM workloads demonstrate that our prototype for live gang
	migration can achieve significant reductions in both network traffic
	and total migration time. 2011 ACM.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20113014169788
	
	Application performance
	
	Co-located
	
	Compression approach
	
	Content similarity
	
	Gigabit Ethernet
	
	Live migrations
	
	Migration time
	
	Network traffic
	
	Power savings
	
	Proof of concept
	
	Prototype implementations
	
	System maintenance
	
	Virtual machines},
  issn = {10828907},
  keywords = {Computer simulation, Arts computing, Computer networks, Ethernet,
	Ethers, Maintenance, Optimization}
}

@ARTICLE{Esfandiarpoor2013,
  author = {Sina Esfandiarpoor and Ali Pahlavan and Maziar Goudarzi},
  title = {Virtual Machine Consolidation for Datacenter Energy Improvement},
  journal = {CoRR},
  year = {2013},
  volume = {abs/1302.2227},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://arxiv.org/abs/1302.2227}
}

@INPROCEEDINGS{Fan2007,
  author = {Fan, Xiaobo and Weber, Wolf-Dietrich and Barroso, Luiz Andre},
  title = {Power provisioning for a warehouse-sized computer},
  booktitle = {Proceedings - International Symposium on Computer Architecture},
  year = {2007},
  pages = {13--23},
  address = {San Diego, CA, United states},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  abstract = {Large-scale Internet services require a computing infrastructure that
	can beappropriately described as a warehouse-sized computing system.
	The cost ofbuilding datacenter facilities capable of delivering a
	given power capacity tosuch a computer can rival the recurring energy
	consumption costs themselves.Therefore, there are strong economic
	incentives to operate facilities as closeas possible to maximum capacity,
	so that the non-recurring facility costs canbe best amortized. That
	is difficult to achieve in practice because ofuncertainties in equipment
	power ratings and because power consumption tends tovary significantly
	with the actual computing activity. Effective powerprovisioning strategies
	are needed to determine how much computing equipmentcan be safely
	and efficiently hosted within a given power budget. In this paper
	we present the aggregate power usage characteristics of largecollections
	of servers (up to 15 thousand) for different classes ofapplications
	over a period of approximately six months. Those observationsallow
	us to evaluate opportunities for maximizing the use of the deployed
	powercapacity of datacenters, and assess the risks of over-subscribing
	it. We findthat even in well-tuned applications there is a noticeable
	gap (7 - 16%)between achieved and theoretical aggregate peak power
	usage at the clusterlevel (thousands of servers). The gap grows to
	almost 40% in wholedatacenters. This headroom can be used to deploy
	additional compute equipmentwithin the same power budget with minimal
	risk of exceeding it. We use ourmodeling framework to estimate the
	potential of power management schemes toreduce peak power and energy
	usage. We find that the opportunities for powerand energy savings
	are significant, but greater at the cluster-level (thousandsof servers)
	than at the rack-level (tens). Finally we argue that systems needto
	be power efficient across the activity range, and not only at peakperformance
	levels. Copyright 2007 ACM.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20074310881240
	
	Power modeling
	
	Power provisioning},
  issn = {10636897},
  keywords = {Telecommunication services, Electric power utilization, Energy efficiency,
	Internet, Mathematical models, Warehouses}
}

@OTHER{Graubner2012,
  abstract = {In the presence of rising costs for energy, infrastructure, cooling
	and power supply, Infrastructure-as-a-Service Cloud computing providers
	are highly interested in increasing the energy efficiency of their
	hardware- and software architectures. In this article, a novel approach
	to virtual machine consolidation for saving energy is presented.
	It is based on energy-efficient storage migration and live migration
	of virtual machines to take advantage of the lacking energy-proportionality
	of commodity hardware. Eucalyptus, an open-source clone of the popular
	Amazon Elastic Compute Cloud, is used to implement the proposed approach.
	Several short- and long-term experiments are presented, demonstrating
	the potential for energy savings in productive Cloud computing environments.
	Quality-of-service violations during the consolidation process are
	addressed.},
  author = {Graubner, P. and Schmidt, M. and Freisleben, B.},
  booktitle = {IT Professional},
  issn = {1520-9202},
  journal = {IT Professional},
  keywords = {Cloud Computing, D.4.2 Storage Management, D.4.7.b Distributed systems,
	Energy Efficiency, Virtualization},
  number = {99},
  pages = {1--1},
  title = {Energy-efficient Virtual Machine Consolidation for Cloud Computing},
  volume = {PP},
  year = {2012}
}

@INPROCEEDINGS{Gupta2011,
  author = {Gupta, S. K S and Gilbert, R.R. and Banerjee, A. and Abbasi, Z. and
	Mukherjee, T. and Varsamopoulos, G.},
  title = {GDCSim: A tool for analyzing Green Data Center design and resource
	management techniques},
  booktitle = {Green Computing Conference and Workshops (IGCC), 2011 International},
  year = {2011},
  pages = {1-8},
  abstract = {Energy consumption in data centers can be reduced by efficient design
	of the data centers and efficient management of computing resources
	and cooling units. A major obstacle in the analysis of data centers
	is the lack of a holistic simulator, where the impact of new computing
	resource (or cooling) management techniques can be tested with different
	designs (i.e., layouts and configurations) of data centers. To fill
	this gap, this paper proposes Green Data Center Simulator (GDCSim)
	for studying the energy efficiency of data centers under various
	data center geometries, workload characteristics, platform power
	management schemes, and scheduling algorithms. GDCSim is used to
	iteratively design green data centers. Further, it is validated against
	established CFD simulators. GDCSim is developed as a part of the
	BlueTool infrastructure project at Impact Lab.},
  doi = {10.1109/IGCC.2011.6008612},
  keywords = {computer centres;energy conservation;energy consumption;environmental
	factors;power aware computing;resource allocation;scheduling;BlueTool
	infrastructure project;GDCSim;computing resource;data center geometries;energy
	consumption;energy efficiency;green data center design;green data
	center simulator;platform power management schemes;resource management
	technique;scheduling algorithm;workload characteristics;Computational
	fluid dynamics;Cooling;Data models;Heating;Resource management;Servers;Thermal
	management;Simulator;data center;energy efficient;green}
}

@INPROCEEDINGS{Halder2012,
  author = {Halder, K. and Bellur, U. and Kulkarni, P.},
  title = {Risk Aware Provisioning and Resource Aggregation Based Consolidation
	of Virtual Machines},
  booktitle = {Cloud Computing (CLOUD), 2012 IEEE 5th International Conference on},
  year = {2012},
  pages = {598--605},
  abstract = {Server consolidation has emerged as an important technique to save
	on energy costs in virtualized datacenters. The issue of instantiation
	of a given set of Virtual Machines (VMs) on a set of Physical Machines
	(PMs) can be thought of as consisting of a provisioning step where
	we determine the amount of resources to be allocated to a VM and
	a placement step which decides which VMs can be placed together on
	a physical machines thereby allocating VMs to PMs. In this paper,
	we introduce a provisioning scheme which takes into account acceptable
	intensity of violation of provisioned resources. In addition we identify
	a serious shortcoming of existing placement schemes that correct
	in our correlation aware placement scheme. We consider correlation
	among aggregated resource demands of VMs while finding the VM-PM
	mapping. Experimental results reveal that our approach leads to a
	significant amount of reduction in the number of servers (up to 32%
	in our settings) required to host 1000 VMs and thus enables us to
	turn off unnecessary servers. It achieves this by packing VMs more
	tightly by correlating resource requirements across the entire set
	of VMs to be placed. We present a comprehensive set of experimental
	results comparing our scheme with the existing provisioning and placement
	schemes.},
  issn = {2159-6182},
  keywords = {computer centres, risk analysis, virtual machines, PM, VM, correlation
	aware placement scheme, physical machines, placement step, resource
	aggregation based consolidation, risk aware provisioning, server
	consolidation, virtual machines, virtualized data centers, Aggregates,
	Correlation, Joints, Measurement, Resource management, Servers, Virtual
	machining, acceptable intensity of violation, consolidation, correlation,
	provisioning}
}

@INPROCEEDINGS{Hirofuchi:2011:RCV:1996121.1996125,
  author = {Hirofuchi, Takahiro and Nakada, Hidemoto and Itoh, Satoshi and Sekiguchi,
	Satoshi},
  title = {Reactive consolidation of virtual machines enabled by postcopy live
	migration},
  booktitle = {Proceedings of the 5th international workshop on Virtualization technologies
	in distributed computing},
  year = {2011},
  series = {VTDC '11},
  pages = {11--18},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1996125},
  doi = {10.1145/1996121.1996125},
  isbn = {978-1-4503-0701-7},
  keywords = {live migration, virtual machine},
  location = {San Jose, California, USA},
  numpages = {8},
  url = {http://doi.acm.org/10.1145/1996121.1996125}
}

@INPROCEEDINGS{Huang2012a,
  author = {Huang, Zhe and Tsang, D.H.K.},
  title = {SLA guaranteed virtual machine consolidation for computing clouds},
  booktitle = {Communications (ICC), 2012 IEEE International Conference on},
  year = {2012},
  pages = {1314--1319},
  abstract = {One of the most attractive features that computing clouds can offer
	is that the data center maintenance cost can be reduced by consolidating
	the workload generated by the virtual machines (VMs) into a few powerful
	physical servers. In this paper, the problem of maximally consolidating
	heterogeneous virtual machines into servers while protecting the
	service level agreement of each virtual machine is investigated.
	A generic and robust VM workload consolidation framework is proposed.
	The proposed framework achieves several attractive properties like
	low maintenance cost, low algorithm complexity, adjustable resource
	provisioning aggressiveness, and good scalability.},
  issn = {1550-3607},
  keywords = {cloud computing, computer centres, virtual machines, SLA guaranteed
	virtual machine consolidation, adjustable resource provisioning aggressiveness,
	cloud computing, data center maintenance cost, maximally consolidating
	heterogeneous virtual machine problem, physical servers, robust VM
	workload consolidation framework, service level agreement protection,
	Forecasting, Hardware, Heuristic algorithms, Relaxation methods,
	Robustness, Servers, Virtual machining}
}

@INPROCEEDINGS{Huang2012,
  author = {Huang, Zhe and Tsang, Danny H. K. and She, James},
  title = {A virtual machine consolidation framework for MapReduce enabled computing
	clouds},
  booktitle = {Proceedings of the 24th International Teletraffic Congress},
  year = {2012},
  series = {ITC '12},
  pages = {26:1--26:8},
  publisher = {International Teletraffic Congress},
  abstract = {In nowadays computing clouds, it is of the cloud providers' economic
	interests to correctly consolidate the workload of the virtual machines
	(VMs) into the suitable physical servers in the cloud data center
	in order to minimize the total maintenance cost. However, during
	the consolidation process, sufficient protection should be provided
	to the service level agreement (SLA) of the VMs. In this paper, the
	VM consolidation problem for MapReduce enabled computing clouds has
	been investigated. In the MapReduce enabled computing clouds, MapReduce
	jobs are carried out by homogeneous MapReduce VM instances that have
	identical hardware resource. Two resource allocation schemes with
	corresponding SLA constraints for the MapReduce VMs and the non-MapReduce
	VMs are proposed. Based on these schemes, the VM consolidation problem
	is modeled as an integer nonlinear optimization problem and an efficient
	algorithm has been proposed to locate its solutions. The results
	show that better VM consolidation performance can be achieved by
	colocating MapReduce instances together with non-MapReduce instances
	in the same set of physical servers.},
  acmid = {2414308},
  articleno = {26},
  isbn = {978-1-4503-1896-9},
  keywords = {cloud computing, computer centres, contract law, integer programming,
	nonlinear programming, resource allocation, virtual machines, MapReduce
	enabled computing clouds, SLA constraint protection, VM consolidation
	problem, cloud data center, cloud provider economic interests, hardware
	resource allocation schemes, homogeneous MapReduce VM instance colocation,
	integer nonlinear optimization problem, nonMapReduce VM, physical
	servers, service level agreement, total maintenance cost minimization,
	virtual machine consolidation framework, Bandwidth, Cloud computing,
	Hardware, Maintenance engineering, Resource management, Servers,
	Vectors},
  location = {Krakow, Poland},
  numpages = {8},
  url = {http://dl.acm.org/citation.cfm?id=2414276.2414308}
}

@INPROCEEDINGS{Humphries2010,
  author = {Humphries, Courtney and Ruth, Paul},
  title = {Towards power efficient consolidation and distribution of virtual
	machines},
  booktitle = {Proceedings of the 48th Annual Southeast Regional Conference},
  year = {2010},
  series = {ACM SE '10},
  pages = {75:1--75:6},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1900109},
  articleno = {75},
  doi = {10.1145/1900008.1900109},
  isbn = {978-1-4503-0064-3},
  keywords = {architecture, distributed/parallel computing, power consumption, power
	management, virtual machines},
  location = {Oxford, Mississippi},
  numpages = {6},
  url = {http://doi.acm.org/10.1145/1900008.1900109}
}

@TECHREPORT{Inc2007,
  author = {Gartner Inc},
  title = {Gartner Estimates ICT Industry Accounts for 2 Percent of Global CO2
	Emissions},
  institution = {Gartner Press Release},
  year = {2007}
}

@MISC{VMwareInc2010,
  author = {VMware Inc},
  title = {VMware Distributed Power Management: Concepts and Usage},
  howpublished = {http://www.vmware.com/resources/techresources/1080},
  month = {4},
  year = {2010}
}

@TECHREPORT{Julia2010,
  author = {Ferran Julia and Jordi Roldan and Ramon Nou and J. Oriol Fito and
	Alexandre Vaque and Inigo Goiri and Josep Lluis Berral},
  title = {EEFSim: Energy Eciency Simulator},
  institution = {Dept. o fComputer Architecture},
  year = {2010},
  owner = {wanglong},
  timestamp = {2013.07.27}
}

@ARTICLE{JyothiSekhar2012,
  author = {JyothiSekhar and GetziJeba and Durga, S.},
  title = {A SURVEY ON ENERGY EFFICIENT SERVER CONSOLIDATION THROUGH VM LIVE
	MIGRATION},
  journal = {International Journal of Advances in Engineering \& Technology},
  year = {2012},
  volume = {5},
  pages = {515--525},
  number = {1},
  abstract = {Virtualization technologies which are heavily relied on by the Cloud
	Computing environments provide the ability to transfer virtual machines
	(VM) between the physical systems using the technique of live migration
	mainly for improving the energy efficiency. Dynamic server consolidation
	through live migration is an efficient way towards energy conservation
	in Cloud data centers.The main objective is to keep the number of
	power-on systems as low as possible and thus reduce the excessive
	power used to run idle servers. This technique of VM live migration
	is being used widely for various system-related issues like load
	balancing, online system maintenance, fault tolerance and resource
	distribution. Energy efficient VM migration becomes a main concern
	as the data centers are trying to reduce the power consumption. Aggressive
	consolidation may even lead to performance degradation and hence
	can result in Service Level Agreement (SLA) violation. Thus there
	is a trade-off between energy and performance. Various protocols,
	heuristics and architectures have been proposed for the energy aware
	server consolidation via live migration of VMs and are the main area
	for this survey.},
  comment = {JyothisekharGetzijeba-36
	
	2013-03-18 10:11:00
	
	±±¾©Íò·½Êý¾Ý¹É·ÝÓÐÏÞ¹«Ë¾},
  keywords = {Cloud computing; Data Center; Energy Efficiency; Live Migration; Virtual
	Machine; VM consolidation},
  refid = {36},
  url = {http://d.g.wanfangdata.com.cn/OAPaper_oai_doaj-articles_3052e13807bc50ea8593ccb5c4997ffb.aspx}
}

@INPROCEEDINGS{Kang2012,
  author = {Kang, Seungmin and Kim, Shin-Gyu and Eom, Hyeonsang and Yeom, Heon
	Y.},
  title = {Towards workload-aware virtual machine consolidation on cloud platforms},
  booktitle = {Proceedings of the 6th International Conference on Ubiquitous Information
	Management and Communication, ICUIMC'12},
  year = {2012},
  pages = {ACM Special Interest Group on Applied Computing (SIGAPP); Ajou University;
	Kyung Hee University; Kyungwon University; Yonsei University; Universiti
	Kuala Lumpur--},
  address = {Kuala Lumpur, Malaysia},
  publisher = {Association for Computing Machinery},
  abstract = {As the cloud markets grow, the cloud providers are faced with new
	challenges such as reduction of power consumption and guaranteeing
	service level agreements (SLAs). One reason for these problems is
	the use of server consolidation policy based on virtualization for
	maximizing the efficiency of resource usage. Because current virtualization
	technologies do not ensure performance isolation among active virtual
	machines (VMs), it is required to consider resource usage pattern
	of VMs to improve total throughput and quality of service. In this
	paper, we propose a new consolidation policy which exploits per-VM
	resource usage monitoring techniques. Specifically, we focus on the
	performance impact of contention in a last-level shared cache (LLC).
	Through our experiments, we have found that the ratio of LLC reference
	is highly associated with cache demand, and a throughput-maximizing
	VM consolidation policy can be devised by using the ratio. 2012 ACM.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20121915000807
	
	Cloud providers
	
	Last level cache contention
	
	Monitoring techniques
	
	Performance impact
	
	Resource usage
	
	Server consolidation
	
	Service Level Agreements
	
	Shared cache
	
	Virtual machines
	
	Virtualizations},
  keywords = {Virtual reality, Cloud computing, Communication, Information management,
	Quality of service}
}

@INPROCEEDINGS{Kansal2010,
  author = {Kansal, Aman and Zhao, Feng and Liu, Jie and Kothari, Nupur and Bhattacharya,
	Arka A.},
  title = {Virtual machine power metering and provisioning},
  booktitle = {Proceedings of the 1st ACM Symposium on Cloud Computing, SoCC '10},
  year = {2010},
  pages = {39--50},
  address = {Indianapolis, IN, United states},
  publisher = {Association for Computing Machinery},
  abstract = {Virtualization is often used in cloud computing platforms for its
	several advantages in efficiently managing resources. However, virtualization
	raises certain additional challenges, and one of them is lack of
	power metering for virtual machines (VMs). Power management requirements
	in modern data centers have led to most new servers providing power
	usage measurement in hardware and alternate solutions exist for older
	servers using circuit and outlet level measurements. However, VM
	power cannot be measured purely in hardware. We present a solution
	for VM power metering, named Joulemeter. We build power models to
	infer power consumption from resource usage at runtime and identify
	the challenges that arise when applying such models for VM power
	metering. We show how existing instrumentation in server hardware
	and hypervisors can be used to build the required power models on
	real platforms with low error. Our approach is designed to operate
	with extremely low runtime overhead while providing practically useful
	accuracy. We illustrate the use of the proposed metering capability
	for VM power capping, a technique to reduce power provisioning costs
	in data centers. Experiments are performed on server traces from
	several thousand production servers, hosting Microsoft's real-world
	applications such as Windows Live Messenger. The results show that
	not only does VM power metering allow virtualized data centers to
	achieve the same savings that non-virtualized data centers achieved
	through physical server power capping, but also that it enables further
	savings in provisioning costs with virtualization. Copyright 2010
	ACM.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20103013100465
	
	Cloud computing
	
	Data centers
	
	Managing resources
	
	MicroSoft
	
	Power Consumption
	
	Power managements
	
	Power metering
	
	Power model
	
	Power usage
	
	Real-world application
	
	Resource usage
	
	Runtime overheads
	
	Runtimes
	
	Virtual machines
	
	Virtualizations},
  keywords = {Windows operating system, Computer simulation, Cost reduction, Distributed
	computer systems, Electric power measurement, Energy management,
	Servers}
}

@INPROCEEDINGS{Khanna2006,
  author = {Khanna, Gunjan and Beaty, Kirk and Kar, Gautam and Kochut, Andrzej},
  title = {Application performance management in virtualized server environments},
  year = {2006},
  pages = {373 - 381},
  address = {Vancouver, BC, Canada},
  note = {Application performance management;Storage elements;System management;Virtual
	Machines;},
  abstract = {As businesses have grown, so has the need to deploy I/T applications
	rapidly to support the expanding business processes. Often, this
	growth was achieved in an unplanned way: each time a new application
	was needed a new server along with the application software was deployed
	and new storage elements were purchased. In many cases this has led
	to what is often referred to as "server sprawl", resulting in low
	server utilization and high system management costs. An architectural
	approach that is becoming increasingly popular to address this problem
	is known as server virtualization. In this paper we introduce the
	concept of server consolidation using virtualization and point out
	associated Issues that arise in the area of application performance.
	We show how some of these problems can be solved by monitoring key
	performance metrics and using the data to trigger migration of Virtual
	Machines within physical servers. The algorithms we present attempt
	to minimize the cost of migration and maintain acceptable application
	performance levels. &copy; 2006 IEEE.},
  copyright = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.},
  journal = {IEEE Symposium Record on Network Operations and Management Symposium},
  key = {Network management},
  keywords = {Administrative data processing;Algorithms;Computer software;Costs;Problem
	solving;Servers;},
  language = {English}
}

@INPROCEEDINGS{Kliazovich2010,
  author = {Kliazovich, D. and Bouvry, P. and Audzevich, Y. and Khan, S.U.},
  title = {GreenCloud: A Packet-Level Simulator of Energy-Aware Cloud Computing
	Data Centers},
  booktitle = {Global Telecommunications Conference (GLOBECOM 2010), 2010 IEEE},
  year = {2010},
  pages = {1-5},
  abstract = {Cloud computing data centers are becoming increasingly popular for
	the provisioning of computing resources. The cost and operating expenses
	of data centers have skyrocketed with the increase in computing capacity.
	Several governmental, industrial, and academic surveys indicate that
	the energy utilized by computing and communication units within a
	data center contributes to a considerable slice of the data center
	operational costs. In this paper, we present a simulation environment
	for energy-aware cloud computing data centers. Along with the workload
	distribution, the simulator is designed to capture details of the
	energy consumed by data center components (servers, switches, and
	links) as well as packet-level communication patterns in realistic
	setups. The simulation results obtained for two-tier, three- tier,
	and three-tier high-speed data center architectures demonstrate the
	effectiveness of the simulator in utilizing power management schema,
	such as voltage scaling, frequency scaling, and dynamic shutdown
	that are applied to the computing and networking components.},
  doi = {10.1109/GLOCOM.2010.5683561},
  issn = {1930-529X},
  keywords = {Internet;computer centres;energy conservation;power aware computing;GreenCloud;data
	center operational costs;energy-aware cloud computing data centers;frequency
	scaling;packet-level communication patterns;packet-level simulator;power
	management schema;voltage scaling;workload distribution;Computational
	modeling;Computer architecture;Data models;Green products;Optical
	switches;Power demand;Servers}
}

@TECHREPORT{Koomey2011,
  author = {Jonathan G. Koomey},
  title = {GROWTH IN DATA CENTER ELECTRICITY USE 2005 TO 2010},
  institution = {Oakland, CA: Analytics Press. August 1.http://www.analyticspress.com/datacenters.html},
  year = {2011}
}

@TECHREPORT{Koomey2007,
  author = {Jonathan G. Koomey},
  title = {ESTIMATING TOTAL POWER CONSUMPTION BY SERVERS IN THE U.S. AND THE
	WORLD},
  institution = {Stanford University},
  year = {2007}
}

@ARTICLE{Kusic2009,
  author = {Kusic, Dara and Kephart, JeffreyO. and Hanson, JamesE. and Kandasamy,
	Nagarajan and Jiang, Guofei},
  title = {Power and performance management of virtualized computing environments
	via lookahead control},
  journal = {Cluster Computing},
  year = {2009},
  volume = {12},
  pages = {1-15},
  number = {1},
  abstract = {There is growing incentive to reduce the power consumed by large-scale
	data centers that host online services such as banking, retail commerce,
	and gaming. Virtualization is a promising approach to consolidating
	multiple online services onto a smaller number of computing resources.
	A virtualized server environment allows computing resources to be
	shared among multiple performance-isolated platforms called virtual
	machines. By dynamically provisioning virtual machines, consolidating
	the workload, and turning servers on and off as needed, data center
	operators can maintain the desired quality-of-service (QoS) while
	achieving higher server utilization and energy efficiency. We implement
	and validate a dynamic resource provisioning framework for virtualized
	server environments wherein the provisioning problem is posed as
	one of sequential optimization under uncertainty and solved using
	a lookahead control scheme. The proposed approach accounts for the
	switching costs incurred while provisioning virtual machines and
	explicitly encodes the corresponding risk in the optimization problem.
	Experiments using the Trade6 enterprise application show that a server
	cluster managed by the controller conserves, on average, 22% of the
	power required by a system without dynamic control while still maintaining
	QoS goals. Finally, we use trace-based simulations to analyze controller
	performance on server clusters larger than our testbed, and show
	how concepts from approximation theory can be used to further reduce
	the computational burden of controlling large systems.},
  doi = {10.1007/s10586-008-0070-y},
  issn = {1386-7857},
  issue = {1},
  keywords = {Power management; Resource provisioning; Virtualization; Predictive
	control},
  language = {English},
  publisher = {Springer US},
  url = {http://dx.doi.org/10.1007/s10586-008-0070-y}
}

@ARTICLE{Lee2012,
  author = {Lee, Young Choon and Zomaya, Albert Y.},
  title = {Energy efficient utilization of resources in cloud computing systems},
  journal = {Journal of Supercomputing},
  year = {2012},
  volume = {60},
  pages = {268--280},
  number = {2},
  abstract = {The energy consumption of under-utilized resources, particularly in
	a cloud environment, accounts for a substantial amount of the actual
	energy use. Inherently, a resource allocation strategy that takes
	into account resource utilization would lead to a better energy efficiency;
	this, in clouds, extends further with virtualization technologies
	in that tasks can be easily consolidated. Task consolidation is an
	effective method to increase resource utilization and in turn reduces
	energy consumption. Recent studies identified that server energy
	consumption scales linearly with (processor) resource utilization.
	This encouraging fact further highlights the significant contribution
	of task consolidation to the reduction in energy consumption. However,
	task consolidation can also lead to the freeing up of resources that
	can sit idling yet still drawing power. There have been some notable
	efforts to reduce idle power draw, typically by putting computer
	resources into some form of sleep/power-saving mode. In this paper,
	we present two energy-conscious task consolidation heuristics, which
	aim to maximize resource utilization and explicitly take into account
	both active and idle energy consumption. Our heuristics assign each
	task to the resource on which the energy consumption for executing
	the task is explicitly or implicitly minimized without the performance
	degradation of that task. Based on our experimental results, our
	heuristics demonstrate their promising energy-saving capability.
	Springer Science+Business Media, LLC 2010.},
  address = {Van Godewijckstraat 30, Dordrecht, 3311 GZ, Netherlands},
  booktitle = {Special issue on Energy-efficient high-performance parallel and distributed
	computing},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20122415109919
	
	Computer resources
	
	Computing system
	
	Energy aware
	
	Energy efficient
	
	Energy use
	
	Performance degradation
	
	Power draw
	
	Reduction in energy consumption
	
	Resource allocation strategies
	
	Resource utilizations
	
	Task consolidation
	
	Virtualizations},
  issn = {09208542},
  keywords = {Energy utilization, Cloud computing, Computer systems, Degradation,
	Energy efficiency, Resource allocation, Scheduling},
  publisher = {Springer Netherlands}
}

@INPROCEEDINGS{Liao2012,
  author = {Liao, Jian-Sheng and Chang, Chi-Chung and Hsu, Yao-Lun and Zhang,
	Xiao-Wei and Lai, Kuan-Chou and Hsu, Ching-Hsien},
  title = {Energy-efficient resource provisioning with SLA consideration on
	cloud computing},
  booktitle = {Proceedings of the International Conference on Parallel Processing
	Workshops},
  year = {2012},
  pages = {206--211},
  address = {Pittsburgh, PA, United states},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  abstract = {Cloud computing aims at reducing energy consumption and maximizing
	resource efficiency without violating service level agreement (SLA).
	To address these important issues, this study proposes an energy-efficient
	resource provisioning technology with SLA consideration for virtual
	machine scheduling. According to SLAs, the resource manager could
	consolidate virtual machines onto the physical machine for meeting
	customers' SLA requests. Experimental results show that the proposed
	approach outperforms other proposed ones in power consumption. 2012
	IEEE.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20125115821833
	
	Energy efficient
	
	Reducing energy consumption
	
	Resource efficiencies
	
	Resource managers
	
	Resource provisioning
	
	Service Level Agreements
	
	Virtual machines
	
	Virtualizations},
  issn = {15302016},
  keywords = {Cloud computing, Computer simulation, Energy conservation, Energy
	efficiency}
}

@INPROCEEDINGS{Lim2009,
  author = {Seung-Hwan Lim and Sharma, B. and Gunwoo Nam and Eun Kyoung Kim and
	Das, C.R.},
  title = {MDCSim: A multi-tier data center simulation, platform},
  booktitle = {Cluster Computing and Workshops, 2009. CLUSTER '09. IEEE International
	Conference on},
  year = {2009},
  pages = {1-9},
  abstract = {Performance and power issues are becoming increasingly important in
	the design of large, cluster-based multi-tier data centers for supporting
	a multitude of services. The design and analysis of such large/complex
	distributed systems often suffer from the lack of availability of
	an adequate physical infrastructure. This paper presents a comprehensive,
	flexible, and scalable simulation platform for in-depth analysis
	of multi-tier data centers. Designed as a pluggable three-level architecture,
	our simulator captures all the important design specifics of the
	underlying communication paradigm, kernel level scheduling artifacts,
	and the application level interactions among the tiers of a three-tier
	data center. The flexibility of the simulator is attributed to its
	ability in experimenting with different design alternatives in the
	three layers, and in analyzing both the performance and power consumption
	with realistic workloads. The scalability of the simulator is demonstrated
	with analyses of different data center configurations. In addition,
	we have designed a prototype three-tier data center on an Infiniband
	Architecture (IBA) connected Linux cluster to validate the simulator.
	Using RUBiS benchmark workload, it is shown that the simulator is
	quite accurate in estimating the throughput, response time, and power
	consumption. We then demonstrate the applicability of the simulator
	in conducting three different types of studies. First, we conduct
	a comparative analysis of the IBA and 10 Gigabit Ethernet (10 GigE)
	under different traffic conditions and with varying size clusters
	for understanding their relative merits in designing cluster-based
	servers. Second, measurement and characterization of power consumption
	across the servers of a three-tier data center is done. Third, we
	perform a configuration analysis of the Web server (WS), Application
	Server (AS), and Database Server (DB) for performance optimization.
	We believe that such a comprehensive simulation infrastructure -
	is critical for providing guidelines in designing efficient and cost-effective
	multi-tier data centers.},
  doi = {10.1109/CLUSTR.2009.5289159},
  issn = {1552-5244},
  keywords = {Linux;computer architecture;computer centres;file servers;local area
	networks;processor scheduling;Ethernet analysis;IBA analysis;Linux
	cluster;MDCSim platform;RUBiS benchmark workload;Web server configuration;application
	level interactions;application server configuration;cluster-based
	server design;communication paradigm;database server configuration;distributed
	systems;infiniband architecture;kernel level scheduling artifacts;multi-tier
	data center simulation;pluggable three-level architecture;power consumption
	measurement;storage capacity 10 Gbit;Analytical models;Availability;Data
	analysis;Energy consumption;Kernel;Linux;Performance analysis;Scalability;Throughput;Virtual
	prototyping}
}

@INPROCEEDINGS{Lin2011,
  author = {Ching-Chi Lin and Pangfeng Liu and Jan-Jan Wu},
  title = {Energy-Aware Virtual Machine Dynamic Provision and Scheduling for
	Cloud Computing},
  booktitle = {Cloud Computing (CLOUD), 2011 IEEE International Conference on},
  year = {2011},
  pages = {736-737},
  abstract = {Power consumption is one of the most critical problems in data centers.
	One effective way to reduce power consumption is to consolidate the
	hosting workloads and shut down physical machines which become idle
	after consolidation. Server consolidation is a NP-hard problem. In
	this paper, a new algorithms Dynamic Round-Robin (DRR), is proposed
	for energy-aware virtual machine scheduling and consolidation. We
	compare this strategy with the GREEDY, ROUNDROBIN and POWERSAVE scheduling
	strategies implemented in the Eucalyptus Cloud system. Our experiment
	results show that the Dynamic Round-Robin algorithm reduce a significant
	amount of power consumption compared with the three strategies in
	Eucalyptus.},
  doi = {10.1109/CLOUD.2011.94},
  issn = {2159-6182},
  keywords = {cloud computing;optimisation;power aware computing;scheduling;virtual
	machines;DRR;GREEDY;NP-hard problem;POWERSAVE;ROUNDROBIN;cloud computing;data
	centers;dynamic round robin;energy aware virtual machine dynamic
	provision;energy aware virtual machine dynamic scheduling;eucalyptus
	cloud system;power consumption;server consolidation;Dynamic scheduling;Heuristic
	algorithms;Power demand;Retirement;Scheduling algorithm;Servers;Virtual
	machining;Cloud Computing;Data Center;Power Saving;Virtual Machine
	Consolidation}
}

@INPROCEEDINGS{Liu2011,
  author = {Liu, Haikun and Xu, Cheng-Zhong and Jin, Hai and Gong, Jiayu and
	Liao, Xiaofei},
  title = {Performance and energy modeling for live migration of virtual machines},
  booktitle = {Proceedings of the 20th international symposium on High performance
	distributed computing},
  year = {2011},
  series = {HPDC '11},
  pages = {171--182},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1996154},
  doi = {10.1145/1996130.1996154},
  isbn = {978-1-4503-0552-5},
  keywords = {energy, live migration, performance model, virtual machine},
  location = {San Jose, California, USA},
  numpages = {12},
  url = {http://doi.acm.org/10.1145/1996130.1996154}
}

@MISC{dcsgsimulator,
  author = {Romonet Ltd},
  title = {Welcome to the DCSG Simulator},
  howpublished = {http://dcsg.bcs.org/welcome-dcsg-simulator},
  owner = {wanglong},
  timestamp = {2013.07.27}
}

@ARTICLE{Meisner2010,
  author = {David Meisner and Thomas F. Wenisch},
  title = {Stochastic Queuing Simulation for Data Center Workloads},
  journal = {Proc. of the Workshop on Exascale Evaluation and Research Techniques
	(EXERT)},
  year = {2010},
  owner = {wanglong},
  timestamp = {2013.07.27}
}

@ARTICLE{Mishra2012,
  author = {Mishra, Mayank and Das, Anwesha and Kulkarni, Purushottam and Sahoo,
	Anirudha},
  title = {Dynamic resource management using virtual machine migrations},
  journal = {IEEE Communications Magazine},
  year = {2012},
  volume = {50},
  pages = {34--40},
  number = {9},
  abstract = {Virtualization is a key concept in enabling the "computing-as-a- service"
	vision of cloud-based solutions. Virtual machine related features
	such as flexible resource provisioning, and isolation and migration
	of machine state have improved efficiency of resource usage and dynamic
	resource provisioning capabilities. Live virtual machine migration
	transfers AstateA of a virtual machine from one physical machine
	to another, and can mitigate overload conditions and enables uninterrupted
	maintenance activities. The focus of this article is to present the
	details of virtual machine migration techniques and their usage toward
	dynamic resource management in virtualized environments. We outline
	the components required to use virtual machine migration for dynamic
	resource management in the virtualized cloud environment. We present
	categorization and details of migration heuristics aimed at reducing
	server sprawl, minimizing power consumption, balancing load across
	physical machines, and so on. We conclude with a discussion of open
	research problems in the area. 2012 IEEE.},
  address = {445 Hoes Lane / P.O. Box 1331, Piscataway, NJ 08855-1331, United
	States},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20123815453740
	
	Dynamic resource management
	
	Dynamic resource provisioning
	
	Flexible resources
	
	Machine state
	
	Maintenance activity
	
	Migration technique
	
	Overload condition
	
	Research problems
	
	Resource usage
	
	Virtual machines
	
	Virtualizations
	
	Virtualized environment},
  issn = {01636804},
  keywords = {Dynamics, Environmental management, Natural resources management,
	Resource allocation, Virtual reality},
  publisher = {Institute of Electrical and Electronics Engineers Inc.}
}

@ARTICLE{Murtazaev2011,
  author = {Murtazaev, Aziz and Oh, Sangyoon},
  title = {Sercon: Server consolidation algorithm using live migration of virtual
	machines for green computing},
  journal = {IETE Technical Review (Institution of Electronics and Telecommunication
	Engineers, India)},
  year = {2011},
  volume = {28},
  pages = {212--231},
  number = {3},
  abstract = {Virtualization technologies changed the way data centers of enterprises
	utilize their server resources. Instead of using dedicated servers
	for each type of application, virtualization allows viewing resources
	as a pool of unified resources, thereby reducing complexity and easing
	manageability. Server consolidation technique, which deals with reducing
	the number of servers used by consolidating applications, is one
	of the main applications of virtualization in data centers. The latter
	technique helps to use computing resources more effectively and has
	many benefits, such as reducing costs of power, cooling and, hence,
	contributes to the Green IT initiative. In a dynamic data center
	environment, where applications encapsulated as virtual machines
	are mapped to and released from the nodes frequently, reducing the
	number of server nodes used can be achieved by migrating applications
	without stopping their services, the technology known as live migration.
	However, live migration is a costly operation; hence, how to perform
	periodic server consolidation operation in a migration-aware way
	is a challenging task. We propose server consolidation algorithm
	- Sercon, which not only minimizes the overall number of used servers,
	but also minimizes the number of migrations. We verify the feasibility
	of our algorithm along with showing its scalability by conducting
	experiments with eight different test cases. Copyright 2011 by the
	IETE.},
  address = {A-109, Kanara Business Centre, off Link Road, Ghatkopar (E), Mumbai,
	400 075, India},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20112414064220
	
	Bin packing problem
	
	Green IT
	
	Live migrations
	
	Server consolidation
	
	Vector-packing problem
	
	Virtualizations},
  issn = {02564602},
  keywords = {Information technology, Algorithms, Lakes, Satellite communication
	systems, Virtual reality},
  publisher = {Medknow Publications and Media Pvt. Ltd}
}

@ARTICLE{Sinha2011,
  author = {Sinha, Richa and Purohit, Nidhi and Diwanji, Hiteshi},
  title = {Power Aware Live Migration for Data Centers in Cloud using Dynamic
	Threshold},
  journal = {International Journal of Computer Technology and Applications},
  year = {2011},
  volume = {02},
  pages = {2041-2046},
  number = {06},
  abstract = {Cloud Computing is one of the fast spreading technologies for providing
	utility-based IT services to its user. Large-scale virtualized data-centers
	are established to meet this requirement. Data centers consumes large
	amount of computation power for providing efficient and reliable
	services to its user. Such large consumption of electrical energy
	has increased operating cost for the service providers as well as
	for the service users. Moreover, a large amount of carbon dioxide
	is emitted, results into increased global warming in near future.
	From our studies we concluded that, power consumption can be reduced
	by live migration of the virtual machines (VM) as required and by
	switching off idle machines. So, we proposed a dynamic threshold
	based approach for CPU utilization for host at data center. This
	consolidation will work on dynamic and unpredictable workload avoiding
	unnecessary power consumption. We will not only meet energy efficiency
	requirement but would also ensure quality of service to the user
	by minimizing the Service Level Agreement violation. We would also
	validate the proposed technique results with higher efficiency},
  comment = {2013-03-18 10:25:00
	
	±±¾©Íò·½Êý¾Ý¹É·ÝÓÐÏÞ¹«Ë¾},
  keywords = {Cloud Computing},
  refid = {38},
  url = {http://d.g.wanfangdata.com.cn/OAPaper_oai_doaj-articles_010f1e395f1b6b965f5c6a2f352522b2.aspx}
}

@ARTICLE{Speitkamp2010,
  author = {Speitkamp, B. and Bichler, M.},
  title = {A Mathematical Programming Approach for Server Consolidation Problems
	in Virtualized Data Centers},
  journal = {Services Computing, IEEE Transactions on},
  year = {2010},
  volume = {3},
  pages = {266-278},
  number = {4},
  abstract = {Today's data centers offer IT services mostly hosted on dedicated
	physical servers. Server virtualization provides a technical means
	for server consolidation. Thus, multiple virtual servers can be hosted
	on a single server. Server consolidation describes the process of
	combining the workloads of several different servers on a set of
	target servers. We focus on server consolidation with dozens or hundreds
	of servers, which can be regularly found in enterprise data centers.
	Cost saving is among the key drivers for such projects. This paper
	presents decision models to optimally allocate source servers to
	physical target servers while considering real-world constraints.
	Our central model is proven to be an NP-hard problem. Therefore,
	besides an exact solution method, a heuristic is presented to address
	large-scale server consolidation projects. In addition, a preprocessing
	method for server load data is introduced allowing for the consideration
	of quality-of-service levels. Extensive experiments were conducted
	based on a large set of server load data from a data center provider
	focusing on managerial concerns over what types of problems can be
	solved. Results show that, on average, server savings of 31 percent
	can be achieved only by taking cycles in the server workload into
	account.},
  doi = {10.1109/TSC.2010.25},
  issn = {1939-1374},
  keywords = {computer centres;mathematical programming;NP-hard problem;mathematical
	programming approach;server consolidation problems;virtualized data
	centers;Computational modeling;Data models;Management;Modeling;Operating
	systems;Resource management;Management of services delivery;data
	center management services;modeling of resources;optimization of
	services systems.}
}

@ARTICLE{Sun2013,
  author = {Sun, Xin and Su, Sen and Yang, Fangchun},
  title = {Adaptive virtual machine replacement for multi-dimensional aware
	server consolidation in data centers},
  journal = {Journal of Information and Computational Science},
  year = {2013},
  volume = {10},
  pages = {633--643},
  number = {3},
  abstract = {The efficiency and flexibility of resource allocation has become a
	major concern in modern data centers recently. For the demand satisfactory
	under changing application workload, adaptive management of the shared
	infrastructure via Virtual Machine (VM) replacement is critical to
	data center providers. In comparison with previous achievements that
	focus on individual VM behavior, we prefer to take into account both
	global replacement cost and integrated resource efficiency for a
	reallocation decision. Motivated by the differences on integrated
	utilization and replacement quantity obtained from different allocating
	schemes, in this paper we map such a VM replacement as a dual-objective
	Vector Packing problem with Minimal Placement Cost (VP-MPC). To solve
	such a NP hardness problem, we develop an Adaptive VM Replacement
	(AVR) scheduling mechanism to obtain the approximate optimal VM replacement
	scheme. AVR is an enhanced grouping genetic algorithm with multi-dimensional
	awareness and joint optimization based on weighted fuzzy logic. We
	have implemented our AVR algorithm in CloudSim and make detailed
	comparisons with several existing studies. The simulation results
	show that our AVR algorithm achieves high efficiency and exhibits
	good balance between integrated utilization and global replacement
	cost. 2013 by Binary Information Press.},
  address = {Flat F 8th Floor, Block 3, Tanner Garden, 18 Tanner Road, Hong Kong},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20131016089900
	
	Data centers
	
	Migration costs
	
	Multi-dimensional aware
	
	Resource-scheduling
	
	Virtual machines},
  issn = {15487741},
  keywords = {Computer simulation, Algorithms, Costs, Fuzzy logic, Optimization,
	Scheduling},
  publisher = {Binary Information Press}
}

@INPROCEEDINGS{Umeno2006a,
  author = {Umeno, Hidenori and Parayno, M.L.C. and Teramoto, K. and Kawano,
	M. and Inamasu, H. and Enoki, S. and Kiyama, M. and Aoyama, T. and
	Fukunaga, T.},
  title = {Performance Evaluation on Server Consolidation Using Virtual Machines},
  booktitle = {SICE-ICASE, 2006. International Joint Conference},
  year = {2006},
  pages = {2730--2734},
  abstract = {A virtual machine (VM) is a logical machine having almost the same
	architecture as a real host machine, running an operating system
	(OS) in it. This is called full visualization where multiple OSs
	can run as is in the real host. Many current industries tend to use
	many virtual servers, which are servers running on VMs, consolidating
	many physical servers into a single or fewer real machines, resulting
	in higher resource utilization and smaller space consumption. This
	is called the server consolidation using VMs. Noticing this tendency
	we evaluate the virtualization overhead by measuring the performance
	of the transaction systems running database servers on VMs. Our research
	objectives are to evaluate the VM overhead and the virtualization
	overhead for heavy database servers running in VMs. We have found
	that the total CPU utilization in the two VMs running database servers
	increases to 2.5 times that in the native system with the same hardware
	resources, that is, requiring each server native CPU utilization
	be less than 40%},
  keywords = {database management systems, file servers, operating systems (computers),
	performance evaluation, virtual machines, CPU utilization, database
	server consolidation, operating system, performance evaluation, virtual
	machine, Costs, Educational institutions, Hardware, Operating systems,
	Resource management, Time measurement, Transaction databases, Virtual
	machining, Virtual manufacturing, Voice mail, Database Server, Operating
	System, Server Consolidation, Virtual Machine, Virtulization Overhead}
}

@INPROCEEDINGS{Van2010,
  author = {Van, Hien Nguyen and Tran, F.D. and Menaud, J.-M.},
  title = {Performance and Power Management for Cloud Infrastructures},
  booktitle = {Cloud Computing (CLOUD), 2010 IEEE 3rd International Conference on},
  year = {2010},
  pages = {329--336},
  abstract = {A key issue for Cloud Computing data-centers is to maximize their
	profits by minimizing power consumption and SLA violations of hosted
	applications. In this paper, we propose a resource management framework
	combining a utility-based dynamic Virtual Machine provisioning manager
	and a dynamic VM placement manager. Both problems are modeled as
	constraint satisfaction problems. The VM provisioning process aims
	at maximizing a global utility capturing both the performance of
	the hosted applications with regard to their SLAs and the energy-related
	operational cost of the cloud computing infrastructure. We show several
	experiments how our system can be controlled through high level handles
	to make different trade-off between application performance and energy
	consumption or to arbitrate resource allocations in case of contention.},
  keywords = {Internet, computer centres, constraint theory, power aware computing,
	resource allocation, virtual machines, SLA violations, cloud computing
	data-centers, constraint satisfaction problems, power consumption,
	power management, resource management framework, virtual machine,
	Cloud computing, Clouds, Dynamic scheduling, Energy consumption,
	Resource management, Time factors, Virtual machining, Cloud Computing,
	Energy, SLA, Virtualization}
}

@ARTICLE{Vogels2008,
  author = {Vogels, Werner},
  title = {Beyond Server Consolidation},
  journal = {Queue},
  year = {2008},
  volume = {6},
  pages = {20--26},
  number = {1},
  month = jan,
  acmid = {1348590},
  address = {New York, NY, USA},
  doi = {10.1145/1348583.1348590},
  issn = {1542-7730},
  issue_date = {January/February 2008},
  numpages = {7},
  publisher = {ACM},
  url = {http://doi.acm.org/10.1145/1348583.1348590}
}

@ARTICLE{Voorsluys2009,
  author = {William Voorsluys and James Broberg and Srikumar Venugopal and Rajkumar
	Buyya.},
  title = {Cost of Virtual Machine Live Migration in Clouds: A Performance Evaluation},
  journal = {Lecture Notes in Computer Science},
  year = {2009},
  volume = {5931},
  pages = {254},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl = {http://adsabs.harvard.edu/abs/2009LNCS.5931..254V},
  archiveprefix = {arXiv},
  doi = {10.1007/978-3-642-10665-1_23},
  eprint = {1109.4974},
  primaryclass = {cs.DC}
}

@MISC{binpacking,
  author = {Weisstein, Eric W},
  title = {"Bin-Packing Problem." From MathWorld--A Wolfram Web Resource},
  howpublished = {http://mathworld.wolfram.com/Bin-PackingProblem.html},
  month = {3},
  year = {2013}
}

@INPROCEEDINGS{Yang2012,
  author = {Yang, Jyun-Shiung and Liu, Pangfeng and Wu, Jan-Jan},
  title = {Workload characteristics-aware virtual machine consolidation algorithms},
  booktitle = {Cloud Computing Technology and Science (CloudCom), 2012 IEEE 4th
	International Conference on},
  year = {2012},
  pages = {42--49},
  abstract = {An energy conservation strategy must address two issues - placement
	of virtual machine images and workload characteristics of virtual
	machines. For performance reason most cloud systems copy a prototype
	image into the local disk of a physical machine before starting a
	virtual machine. If the physical machine that stores the image of
	a virtual machine is off-line, then we cannot run this virtual machine.
	The workload characteristics of virtual machines determine whether
	it is data-intensive or CPU-intensive. We assume that the system
	has a distributed file system therefore a physical machine can run
	any virtual machine even if it does not have the image. However,
	we observe that the performance of a data-intensive virtual machine
	running on a physical machine without its image could result in 60%
	performance loss compared with running the same virtual machine on
	a physical machine that has the virtual machine image. On the other
	hand, the performance of a CPU-intensive virtual machine is almost
	independent of whether the physical machine has the image or not.
	As a result, an energy conservation algorithm must consider the workload
	characteristic of a virtual machine when finding a physical machine
	to run it, especially for data-intensive virtual machines. This paper
	proposes a workload characteristics-aware virtual machine consolidation
	algorithms. We propose an approximation algorithm and two dynamic
	programmings to consolidate virtual machines and reduce the number
	of physical machines. We conduct experiments and compare the numbers
	of physical machines used by our approximation algorithm with the
	optimal number of physical machines found by our dynamic programming.
	The experiment results indicate that our approximation algorithm
	finds good solutions much faster than the dynamic programming.},
  keywords = {approximation theory, cloud computing, distributed databases, dynamic
	programming, energy conservation, virtual machines, CPU-intensive
	virtual machine, approximation algorithm, cloud systems, data-intensive
	virtual machine, distributed file system, dynamic programming, energy
	conservation strategy, physical machine, prototype image, virtual
	machine image placement, workload characteristics-aware virtual machine
	consolidation algorithms, Approximation algorithms, Approximation
	methods, Cloud computing, Energy conservation, Equations, Heuristic
	algorithms, Virtual machining, Cloud Computing, Energy Conservation,
	Machine Consolidation, Virtual}
}

@INPROCEEDINGS{Ye2010,
  author = {Ye, Kejiang and Huang, Dawei and Jiang, Xiaohong and Chen, Huajun
	and Wu, Shuang},
  title = {Virtual Machine Based Energy-Efficient Data Center Architecture for
	Cloud Computing: A Performance Perspective},
  booktitle = {2010 IEEE/ACM Int'l Conference on Green Computing and Communications
	\&amp;amp; Int'l Conference on Cyber, Physical and Social Computing},
  year = {2010},
  pages = {8--},
  address = {HangZhou, China},
  abstract = {Virtual machine technology is widely applied to modern data center
	for cloud computing as a key technology to realize energy-efficient
	operation of servers. Server consolidation achieves energy efficiency
	by enabling multiple instantiations of operating systems (OSes) to
	run simultaneously on a single physical machine. While, live migration
	of virtual machine can transfer the virtual machine workload from
	one physical machine to another without interrupting service. However,
	both the two technologies have their own performance overheads. There
	is a tradeoff between the performance and energy efficiency. In this
	paper, we study the energy efficiency from the performance perspective.
	Firstly, we present a virtual machine based energy-efficient data
	center architecture for cloud computing. Then we investigate the
	potential performance overheads caused by server consolidation and
	live migration of virtual machine technology. Experimental results
	show that both the two technologies can effectively implement energy-saving
	goals with little performance overheads. Efficient consolidation
	and migration strategies can improve the energy efficiency.},
  comment = {2010-01-01
	
	2013-03-18 17:25:00
	
	±±¾©Íò·½Êý¾Ý¹É·ÝÓÐÏÞ¹«Ë¾
	
	eng},
  keywords = {Energy Efficiency; Live Migration; Server Consolidation; Virtual Machine},
  refid = {130},
  url = {http://d.g.wanfangdata.com.cn/NSTLHY_NSTL_HYCC0210539487.aspx}
}

@INPROCEEDINGS{Yin2012,
  author = {Yin, Bo and Lin, Lin},
  title = {Energy reducing dynamic multi-dimensional resource allocation in
	cloud data center},
  booktitle = {14th Asia-Pacific Network Operations and Management Symposium: "Management
	in the Big Data and IoT Era", APNOMS 2012 - Final Program},
  year = {2012},
  pages = {KICS KNOM; IEICE ICM--},
  address = {Seoul, Korea, Republic of},
  publisher = {IEEE Computer Society},
  abstract = {Consolidation virtual machine (VM) on fewer physical servers is an
	efficient way to reduce energy consumption in data center. However,
	VMs often have inherent dependencies which bring complex load interactions
	among the underlying physical servers. Unreasonable migration will
	lead to a decline in network performance. In this paper, aiming at
	energy saving, we propose an application-aware policy in VM consolidation
	process. Moreover, in order to guarantee that the migrated VMs can
	be efficiently placed on physical servers determined by the application-aware
	policy, we also propose a multi-dimensional resource allocation algorithm
	(MDRA). Experiment results show that the proposed application-aware
	policy can efficiently reduce energy consumption as well as improving
	network performance. And the proposed MDRA algorithm can ensure the
	effectiveness of our policy. 2012 IEEE.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20130115861486
	
	Cloud data
	
	Complex loads
	
	Consolidation process
	
	Data centers
	
	multi-dimensional
	
	Resource allocation algorithms
	
	Virtual machines},
  keywords = {Information management, Algorithms, Clouds, Energy policy, Energy
	utilization, Network performance, Optimization, Resource allocation}
}

@INPROCEEDINGS{Yuan2012,
  author = {Yuan, Jingling and Jiang, Xing and Zhong, Luo and Yu, Hui},
  title = {Energy aware resource scheduling algorithm for data center using
	reinforcement learning},
  booktitle = {Proceedings - 2012 5th International Conference on Intelligent Computation
	Technology and Automation, ICICTA 2012},
  year = {2012},
  pages = {435--438},
  address = {Zhangjiajie, Hunan, China},
  publisher = {IEEE Computer Society},
  abstract = {More and more attention is paid for energy consumption aware and power
	control for data center with the emergency of energy crisis. The
	use of virtualization technology makes it possible for dynamic configuration
	of data center resources. The N:1 mapping visualization technology
	is employed to integrate many physical machines into an virtual resource
	pool to control resources centralized, and then reinforcement learning
	is applied to resource management and decision making for an uncertain
	task flow data center. Finally, an automatic resource control algorithm
	with energy consumption aware is proposed. This algorithm is implemented
	in the CloudSim platform to improve the energy consumption of the
	data center. The experimental results show that our algorithm can
	reduce about 40% of the energy consumption of the non-power-aware
	data center and reduce 1.7% of that of the greedy scheduling algorithm
	in data center. 2012 IEEE.},
  comment = {Compilation and indexing terms, Copyright 2013 Elsevier Inc.
	
	20121114849994
	
	Data centers
	
	Dynamic allocation
	
	Dynamic configuration
	
	Energy aware
	
	Energy crisis
	
	Resource control algorithms
	
	Resource management
	
	Resource scheduling algorithms
	
	Task flows
	
	Virtual resource
	
	Virtualizations
	
	Visualization technologies},
  keywords = {Information management, Algorithms, Data visualization, Energy policy,
	Energy utilization, Power control, Reinforcement learning, Technology,
	Visualization}
}

